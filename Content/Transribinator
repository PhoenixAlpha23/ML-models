{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:52:57.491563Z","iopub.execute_input":"2025-04-06T11:52:57.491897Z","iopub.status.idle":"2025-04-06T11:52:57.496761Z","shell.execute_reply.started":"2025-04-06T11:52:57.491863Z","shell.execute_reply":"2025-04-06T11:52:57.495773Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# youtube-transcript-api Method","metadata":{}},{"cell_type":"code","source":"pip install youtube-transcript-api","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:53:02.764890Z","iopub.execute_input":"2025-04-06T11:53:02.765189Z","iopub.status.idle":"2025-04-06T11:53:06.176764Z","shell.execute_reply.started":"2025-04-06T11:53:02.765166Z","shell.execute_reply":"2025-04-06T11:53:06.175893Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (1.0.3)\nRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (0.7.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\nfrom urllib.parse import urlparse, parse_qs\n\n# Extract video ID from URL\ndef extract_video_id(url):\n    parsed = urlparse(url)\n    if 'youtu.be' in parsed.netloc:\n        return parsed.path.lstrip('/')\n    elif 'youtube.com' in parsed.netloc:\n        return parse_qs(parsed.query).get('v', [None])[0]\n    return None\n\n# Fetch plain captions only\ndef get_transcript_text(video_id):\n    try:\n        transcripts = YouTubeTranscriptApi.list_transcripts(video_id)\n        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n\n        # Just the spoken text, no timestamps/metadata\n        transcript_text = \" \".join([entry['text'] for entry in transcript])\n        return transcript_text\n\n    except TranscriptsDisabled:\n        print(\"‚ùå Transcripts are disabled for this video.\")\n    except NoTranscriptFound:\n        print(\"‚ùå No transcript found (not available in English or at all).\")\n    except VideoUnavailable:\n        print(\"‚ùå Video is unavailable.\")\n    except Exception as e:\n        print(f\"‚ùå Unexpected error: {e}\")\n    \n    return None\n\n# Example usage\nurl = \"https://youtu.be/GuqAUv4UKXo?si=-5-HgxwQ5HctzBqY\"\nvideo_id = extract_video_id(url)\nprint(\"üéØ Video ID:\", video_id)\n\ntranscript_text = get_transcript_text(video_id)\n\nif transcript_text:\n    print(\"\\nüìù Captions Only:\\n\")\n    print(transcript_text)\nelse:\n    print(\"\\n‚ö†Ô∏è No captions could be extracted.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:02:42.322919Z","iopub.execute_input":"2025-04-06T12:02:42.323231Z","iopub.status.idle":"2025-04-06T12:02:43.682920Z","shell.execute_reply.started":"2025-04-06T12:02:42.323209Z","shell.execute_reply":"2025-04-06T12:02:43.682178Z"}},"outputs":[{"name":"stdout","text":"üéØ Video ID: GuqAUv4UKXo\n\nüìù Captions Only:\n\nSatya nadela thank you so much for doing this I want to be very very respectful of your time the first question is the internet is AB Buzz with conversation of Satya Nela said that SAS is dead now I know you know that's not exactly what you said and the internet has lost Nuance over time but I'd love for you to tell me how that shift happens from SAS all the way to agents yeah I mean to me whenever there's been a real platform shift the core application architectures have changed right I mean if you look back let's go all the way back to when the relational database was born right that was the first time we really said oh wow I can separate out my data tier from my application right before that we were building these essentially Isam databases right into the app and then we said no no no let's have relational algebra I have SQL I have data and then I can build my business Logic on top of it then of course other platforms came like the web and what have you and then we said oh what's an end tier way to write application how should I restructure my business logic I think that something of that scale or if not more is going to happen again with the application logic right and this time around the thing about agents is they are not going to be bound to essentially anyone's SAS application and its data right so I'll have an agentic sort of view where the task the intent and I will go operate uh and orchestrate uh all the logic across multiple SAS applications right I'll go call a bunch of AP through through tools use so I'll call a bunch of apis I will in fact Mo I'll post Trin my model to know about multiple SAS applications in the agent tier and so that's what's going to happen so I think what'll happen is these crud I mean SAS applications are a crud database with a lot of business logic so the crud database will then get orchestrated outside of the business logic tier of just the SAS application is what I mean is going to happen like right right now in my own use case I go to co-pilot I say at sales which is actually touching Dynamic CRM brings back whatever the account information then it brings back information from Office 365 I put it into pages I share it with people the entire workflow right I never I mean everybody talks about their CRM database but anybody nobody uses it because you know when was the last time I logged into CRM never except now I'm every day querying my CRM database because it's so much easier because I it's one agent away and it's working with all the other agents so that is what's going to be the change and when you're hiring people I think in the future you'll now hire people plus you know their workflows that's exactly right and in fact that's a way to think about it it's a swarm of Agents uh I mean it in a praic level I kind of look at it and say it's not like when you hire a data analyst you don't you hire them and their spreadsheets yeah that's kind of what it is right so it's like agents are going to I think two years from now we're going to say yeah agents yeah I build them like all day like like I build docks and spreadsheets and I think that's going I come with a basket of them there you go I have a basket of my agents and and you know like get like I already see that right like you know every SharePoint like then like I have a leadership meeting uh and a leadership team in which there's like all these documents the best grounding data is all in there so I just have a simple agent now which is a SharePoint agent that I'm always addressing and and it's fantastic not to just have to go to a separate entity and you know query it but to have it right there a follow-up question here is how does India stay competitive as this changes because you look at when the llms first came out first became popular uh we always said that if India can build foundational models and sort of do what the West has done that'll be a Advantage for us but we're now see starting to see many of those get commoditized and we're starting to see that the real mode is the ability to keep coming up with breakthroughs if you had to pick something that India can do now that is still defensible in the next few years what would that be yeah mean like it's not just a uh India a common because it it's a common for all of us right I mean you know at the end of the day um I think you really want to take what maybe commodity and then do higher value and then if that higher value thing becomes commodity you have to be ready to commoditize that and move on to the next because that's the thing in Tech right there is no franchise value right so whenever you think quote unquote these Moes and so on are really overstated uh sometimes because you can't really fall in love with your own Mo because it'll get attacked that said I think India has tremendous opportunity right if I think about uh the total developer Community here the entrepreneurial energy here the application space right when I think about all this quick Commerce work that's happening that's pretty unique so whoever builds you know AI applied to that here SAS companies out of here nearly taking the business model disruption even right I mean I think the Next Generation SAS company that says you know what I'm going to embrace these agents uh in fact I'll expose them as first class agents right into copilot in fact change even my business model around it that's a massive opportunity in fact it's a massive attack Vector on any existing SAS company uh that may have a massive Mo quote unquote right so I think that things like that uh and by the way even on the llm space right you know there's the design space is not narrow uh when I talk to customers that's why we are building out Foundry such that we can even be distribution for people who are bu building purpose-built models for Industries you're giv them customers yeah so yeah we're going to bring them customers but also you can build a great llm or a great Foundation model uh for different Sciences uh for different Industries for different roles that are optimized for cogs for latency uh so I think the design space is large enough uh that it may not be just this one model that rules them all uh but there will be in every layer of the tech stack opportunities for innovation that's fantastic I want to ask you a more personal question let's say if you were 25 years old you were sitting out of India let's say you're an engineer by training and you seeing all of this happen you're seeing all these new models come out you're also seeing the ambiguity that you and everyone else are facing right how would you tackle that how would you upskill if you were young again that's a great one it's you know in fact the way I think um one has to deal with both the pace and the scale of innovation is to be very good at sampling with agility is what I describe it like so that means for example the guidance I give ourselves as a company is keep on the frontier and be ready for the next drop so experiment yeah not not experiment like it's kind of like you want to work in multiple gears so you're all the time sort of looking at what's coming and saying what is The Impossible thing that I can make possible with what's coming while I am then making what I built yesterday optimal optimized for cogs for latency for deployment so that two gears you have to simultaneously work on it so it's I mean experimentation is obviously part of it but that you you can't say I'm going to build this and then I'll go to next you're simultaneously working with some Frontier thing where you're making something that is impossible today more possible because of what's coming while you're optimizing that I think is the way at least as a software developer you have to sort of work in this age of AI more so like even in Motors law like you know we us to do that but this is sort of you know when every six month every three months when the performance is doubling that's a like even for Tech that's not something we're used to yeah I mean I can give you an example of this I just tried trellis which is your text to 3D model and I was blown away I was like this is so good and I was able to try it on my local computer and I said imagine this in 2 years it's sort of like the gbd 3.5 right now and then in 2 years is going to get good are there any other things that you've seen in research level or the demo level where you've seen it and you think it's going to play out but in 5 years I think the thing that I'm most excited about or um is on what will happen when you know this particular model architecture or other model architecture breakthroughs will have on science right I mean if you sort of start saying wow if like even start with chemistry right we now have good models for doing novel um new materials right I mean in Material Science like when I think about our data center and we say hey we want to build a more sustainable future whether it's steel or what it's all about Material Science so having models that impact chemistry biology is probably the hardest that's where I think we're very very excited about even some of the new models that we built uh for doing you know molecular Dynamics right which is one of the you know like one thing is to you know be able to model a protein structure but to be able to then model the entire Dynamic nature nature of a molecule that I think is going to be breakthrough in something like drug Discovery so science probably will be the biggest especially the combination of progress in Ai and AI for Science and maybe Quantum that to me might be the next big breakthrough uh where science itself is computed interesting I have one last question right which is you spoke about how these models are getting better every 3 months every four months but I've noticed a problem with Legacy businesses I've meet people who say I tried this model a year ago it was me it had hallucination and then they never give it another shot and this seems to be a problem right which is a bunch of people use a specific type of model many years ago or many months ago and then don't try it again what's the best method what what's your advice to them yeah and that that that would be a big mistake right so which is in some sense you really want to as I said that's why you want to be able to find some place where you can deploy something um and then it's path dependent right all strategy is path dependent if you don't get started you will never get shots on goal yeah and like one of my uh your friends once says to me you can never get fit by watching others go to the gym so you got better me in the gym every day lifting weights uh if you want to have a shot so I think the best way to do it is sample the best you know figure out how to take the most high ambitious scenario and then start deploying at scale what makes sense for you from an economics and scenario perspective if you care about hallucination there are thousand ways to get rid of hallucinations like you grounding now yeah that's right grounding is one but quite frankly if really you don't want to use an llm go use just regular machine learning right if that is like if you're so worried about sort of the 99.9 percentile don't use some of these things where there are airin because that's why I think evals are important and really being driven by what's your aound for humans or for models and then using that as the real criteria but then keep at it interesting thank you so much this was an amazing conversation I learned a lot I'm sure people watching learned a lot as well thank you sa absolutely such a pleasure thank you [Music]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGROQ_API_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:54:45.490045Z","iopub.execute_input":"2025-04-06T11:54:45.490380Z","iopub.status.idle":"2025-04-06T11:54:45.655302Z","shell.execute_reply.started":"2025-04-06T11:54:45.490357Z","shell.execute_reply":"2025-04-06T11:54:45.654601Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import requests\nimport json\nfrom langchain.llms.base import LLM\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom pydantic import BaseModel\nfrom typing import Optional, List, Dict, Any\nimport os\n\nprompt_template = \"\"\"\nYou are a top-tier content strategist known for writing highly engaging and informative Twitter threads.\n\nGiven the transcript of a YouTube video, generate a multi-threaded Twitter chain with these characteristics:\n\nüß≤ 1. Start with a **powerful 1-liner hook** to capture attention.\nüßµ 2. Create a **chain of 5‚Äì8 concise tweets**, each expanding on key insights or concepts from the video.\n‚ú® 3. Format the tweets for **maximum readability and virality**:\n    - Use emojis strategically\n    - Use bold or CAPS for emphasis\n    - Use hooks, numbered lists, or cliffhangers to keep readers scrolling\nüì£ 4. End with a **closing tweet** that summarizes the value or gives a strong CTA (e.g., save, like, share, follow).\n\nTranscript:\n{transcript}\n\nYour response should contain each tweet as a **separate line**, exactly how they‚Äôd be posted in a Twitter thread.\n\"\"\"\n\nclass GroqLLM(LLM, BaseModel):\n    api_key: str = GROQ_API_KEY\n    model_name: str = \"gemma2-9b-it\"\n    temperature: float = 0.7\n    max_tokens: int = 2048\n\n    @property\n    def _llm_type(self) -> str:\n        return \"groq\"\n\n    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        payload = {\n            \"model\": self.model_name,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens\n        }\n\n        response = requests.post(\n            \"https://api.groq.com/openai/v1/chat/completions\",\n            json=payload,\n            headers=headers\n        )\n\n        response_text = response.text\n        print(\"Raw API Response:\", response_text)  # Optional debugging\n\n        if response.status_code != 200:\n            return f\"[ERROR] Groq API: {response.status_code} - {response_text}\"\n\n        try:\n            response_json = response.json()\n            return response_json[\"choices\"][0][\"message\"][\"content\"]\n        except json.JSONDecodeError:\n            return \"[ERROR] Invalid JSON from Groq API\"\n\n    @property\n    def _identifying_params(self) -> Dict[str, Any]:\n        return {\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens\n        }\n\ndef generate_twitter_thread_from_transcript(transcript_text: str) -> str:\n    if not transcript_text or transcript_text.startswith(\"‚ùå\"):\n        return transcript_text\n\n    try:\n        llm = GroqLLM()\n        prompt = PromptTemplate(template=prompt_template, input_variables=[\"transcript_text\"])\n        chain = prompt | llm | RunnablePassthrough()\n        thread = chain.invoke({\"transcript\": transcript_text})\n        return thread\n    except Exception as e:\n        return f\"[ERROR] LLM processing failed: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:59:38.925143Z","iopub.execute_input":"2025-04-06T11:59:38.925461Z","iopub.status.idle":"2025-04-06T11:59:38.939310Z","shell.execute_reply.started":"2025-04-06T11:59:38.925439Z","shell.execute_reply":"2025-04-06T11:59:38.938449Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"generate_twitter_thread_from_transcript(transcript_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:59:43.869411Z","iopub.execute_input":"2025-04-06T11:59:43.869803Z","iopub.status.idle":"2025-04-06T11:59:44.518517Z","shell.execute_reply.started":"2025-04-06T11:59:43.869772Z","shell.execute_reply":"2025-04-06T11:59:44.517632Z"}},"outputs":[{"name":"stdout","text":"Raw API Response: {\"id\":\"chatcmpl-254690e8-df77-45ad-af07-cb446813b5d9\",\"object\":\"chat.completion\",\"created\":1743940784,\"model\":\"gemma2-9b-it\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"ü§Ø Is SaaS REALLY dead? ü§î Satya Nadella weighs in on the evolution of platforms \\u0026 the rise of AI agents.  \\n\\nüßµ Let's break down his insights: \\n\\n1. Major platform shifts ALWAYS change core app architectures. Think about it: relational databases revolutionized how we handle data üóÑÔ∏è. \\n\\n2. Before databases, data was embedded directly in applications. üß±  Then came SQL \\u0026 data separation, paving the way for more flexible business logic. üí°\\n\\n3.  The web was another game-changer üåê . Each platform shift brings new possibilities \\u0026 challenges.\\n\\n4.  Now we're at the cusp of AI agent-driven platforms. ü§ñ  They'll likely change how we interact with software and information itself.\\n\\n5.  Nadella's point: Don't dismiss SaaS entirely.  It's evolving, just like every other major platform before it. üìà\\n\\nWant to dive deeper into this fascinating evolution? Watch the full interview! ‚û°Ô∏è [link to YouTube video]  \\n\\n#SaaS #AI #TechTrends #FutureofWork #SatyaNadella  \\n\\n\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"queue_time\":0.0209279,\"prompt_tokens\":423,\"prompt_time\":0.02473314,\"completion_tokens\":239,\"completion_time\":0.434545455,\"total_tokens\":662,\"total_time\":0.459278595},\"usage_breakdown\":{\"models\":null},\"system_fingerprint\":\"fp_10c08bf97d\",\"x_groq\":{\"id\":\"req_01jr5fh3wkfhwtnga53m58mkg0\"}}\n\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"ü§Ø Is SaaS REALLY dead? ü§î Satya Nadella weighs in on the evolution of platforms & the rise of AI agents.  \\n\\nüßµ Let's break down his insights: \\n\\n1. Major platform shifts ALWAYS change core app architectures. Think about it: relational databases revolutionized how we handle data üóÑÔ∏è. \\n\\n2. Before databases, data was embedded directly in applications. üß±  Then came SQL & data separation, paving the way for more flexible business logic. üí°\\n\\n3.  The web was another game-changer üåê . Each platform shift brings new possibilities & challenges.\\n\\n4.  Now we're at the cusp of AI agent-driven platforms. ü§ñ  They'll likely change how we interact with software and information itself.\\n\\n5.  Nadella's point: Don't dismiss SaaS entirely.  It's evolving, just like every other major platform before it. üìà\\n\\nWant to dive deeper into this fascinating evolution? Watch the full interview! ‚û°Ô∏è [link to YouTube video]  \\n\\n#SaaS #AI #TechTrends #FutureofWork #SatyaNadella  \\n\\n\""},"metadata":{}}],"execution_count":10}]}